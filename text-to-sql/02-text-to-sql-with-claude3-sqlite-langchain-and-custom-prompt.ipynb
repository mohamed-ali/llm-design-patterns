{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acc59f1-1ab4-4415-a124-051145a83075",
   "metadata": {},
   "source": [
    "# 02 - Data Analysis with Text-to-SQL: Leveraging Anthropic Claude 3 on Amazon Bedrock with Custom Prompts and SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503a637-2b57-4b88-a85a-d4ef068a86d6",
   "metadata": {},
   "source": [
    "This notebook demonstrates a practical approach to enabling natural language querying of structured data using Large Language Models (LLMs) and SQLite. We leverage Anthropic's Claude to translate plain English questions into SQL queries, executed against a local SQLite database instance to mimic a SQL database without external dependencies. By combining LLM capabilities with SQL, we bridge the gap between non-technical users and data retrieval, enabling intuitive data exploration without the need for SQL proficiency. Techniques for prompt engineering and query optimization are also explored.\n",
    "\n",
    "In contrast to the previous notebook, we delve deeper into how to customize and fine-tune the prompt to enhance the accuracy of the SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ef8f67-7074-436e-9d7a-ee186d0c420c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752042f2-229f-424b-a6bc-230c6df94a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-community langchain-aws\n",
    "%pip install -q sqlfluff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d582dfc-f67f-48b7-a2ed-cd44c037ccdc",
   "metadata": {},
   "source": [
    "Restart the kernel after installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a19237-5258-437c-be1d-c9d6db4a1940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef28db63-84a8-4162-a9b6-c99b6e6f1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8e009-86b3-49af-a292-b59d083af55a",
   "metadata": {},
   "source": [
    "> This notebook was tested with a kernel with python 3.10.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212eb673-2de4-463f-9cac-f19aa7efef04",
   "metadata": {},
   "source": [
    "## 1. Explore data\n",
    "\n",
    "The data is exported from the [country profile of Tunisia on Harvard Economic Atlas](https://atlas.cid.harvard.edu/explore?country=223&queryLevel=location&product=undefined&year=2021&productClass=HS&target=Product&partner=undefined&startYear=undefined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19a7b74-0174-4bb9-9fee-299dd9b9ea9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb5202b-f1d2-461a-a909-923938601f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'What did Tunisia export in 2021_.csv'  'What did Tunisia import in 2021_.csv'\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11dfb385-930f-4442-a592-919a8707e951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_data_df = pd.read_csv(\"data/What did Tunisia export in 2021_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d58a28c-42a7-4921-80aa-5c58a8c7fb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gross Export</th>\n",
       "      <th>Share</th>\n",
       "      <th>Code</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horses</td>\n",
       "      <td>109905</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0101</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fowl</td>\n",
       "      <td>284920</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0105</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other live animals</td>\n",
       "      <td>36664</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0106</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poultry</td>\n",
       "      <td>3507712</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0207</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other meat</td>\n",
       "      <td>1087</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0208</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Gross Export     Share  Code       Sector\n",
       "0              Horses        109905  0.000539  0101  Agriculture\n",
       "1                Fowl        284920  0.001396  0105  Agriculture\n",
       "2  Other live animals         36664  0.000180  0106  Agriculture\n",
       "3             Poultry       3507712  0.017193  0207  Agriculture\n",
       "4          Other meat          1087  0.000005  0208  Agriculture"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4928c651-d3ab-449f-bf0d-73505f984f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207c0539-3edc-4be0-b49a-23e6a48ca507",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_data_df[\"year\"] = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf01e1-975e-4744-91fc-15b7c4c8c0d0",
   "metadata": {},
   "source": [
    "## 2. Important Design Choices and Decisions\n",
    "\n",
    "Allowing large language models to prepare SQL queries to run against a database should be done with great caution and appropriate safeguards in place. We also need to recognize and work around the variety of database systems and SQL syntax variations when developing AI assistants that may access databases.\n",
    "\n",
    "To achieve this, please consider the following recommendations when designing agents/assistants that can access SQL databases:\n",
    "\n",
    "1. **Never allow the agent to perform write operations** to reduce the risk of SQL injection attacks.\n",
    "2. The LLM agent should run with a user that has **read-only permission against a selection of tables**.\n",
    "   - This reinforces and emphasizes point 1.\n",
    "3. When possible, **use aggregated or materialized views** instead of querying the base tables directly. This will speed up the queries and reduce the load on the database.\n",
    "4. **Limit the agent's access to only the required SQL tables** based on the expected user queries.\n",
    "\n",
    "To control access to the database during the engagement, we will help you build a Lambda function that wraps the functionality of the LLM assistant. This Lambda function can be easily integrated with the remaining components of your system. By limiting the access permissions of the Lambda function to read-only from the SQL database, we can effectively limit the permissions of the LLM assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ade97b-0b24-4275-9fc7-52fe105c139e",
   "metadata": {},
   "source": [
    "## 3. Store data as SQLite db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e4ec8-ce7c-4046-b63c-44f1bad81432",
   "metadata": {},
   "source": [
    "In this demonstration, we use SQLite to mock the SQL database. You can validate your initial proof of concept using SQLite, then move to another production grade database for the pilot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f024c2-151d-43ee-a21b-3ecb878e9cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create an empty SQLite db\n",
    "conn = sqlite3.connect(\"/tmp/tunisia-exports.db\")\n",
    "c = conn.cursor()\n",
    "# Write the pandas dataframe data into the SQLite db\n",
    "properties_data_df.to_sql(\"tunisia_exports_table\", conn, if_exists=\"replace\", index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a03994-2bfd-43c6-a9e8-f2f9fd542277",
   "metadata": {},
   "source": [
    "## 3. Prepare an LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38910137-c8d4-472e-ba1a-fba6580f3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock_client = boto3.client(\"bedrock\", region_name=\"us-west-2\")\n",
    "bedrock_runtime_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba6e147-2d82-4c0a-a817-beb8f76051da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_foundation_models = bedrock_client.list_foundation_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1aa495-df03-4f31-b62f-28186b3186fc",
   "metadata": {},
   "source": [
    "Uncomment the following to see the full list of models on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd30a2a-1799-42ee-9189-f3e7c968307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# available_foundation_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980396c7-e244-4a71-8492-58f3ee981759",
   "metadata": {},
   "source": [
    "Below we keep only models from the Anthropic Claude family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2a4e75-292d-4e2e-b522-5fe1370c89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_models_on_bedrock = [\n",
    "    m for m in available_foundation_models[\"modelSummaries\"]\n",
    "    if \"Claude\" in m[\"modelName\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e97517-f3e4-4ec5-a8bc-bef0aac53a5c",
   "metadata": {},
   "source": [
    "Below we extract the model ids for models in the Anthropic Claude family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6b51d2-cd31-4e40-812b-a333de38f9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anthropic.claude-instant-v1:2:100k',\n",
       " 'anthropic.claude-instant-v1',\n",
       " 'anthropic.claude-v2:0:18k',\n",
       " 'anthropic.claude-v2:0:100k',\n",
       " 'anthropic.claude-v2:1:18k',\n",
       " 'anthropic.claude-v2:1:200k',\n",
       " 'anthropic.claude-v2:1',\n",
       " 'anthropic.claude-v2',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0:28k',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0:200k',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0:48k',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0:200k',\n",
       " 'anthropic.claude-3-haiku-20240307-v1:0',\n",
       " 'anthropic.claude-3-opus-20240229-v1:0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[\"modelId\"] for m in claude_models_on_bedrock]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33a6b2-491b-4262-9d78-b0c241c9e9a4",
   "metadata": {},
   "source": [
    "We pick the Claude haiku model for the first experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cba48e4-e5d1-4a43-b0c6-8d340eeca576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24dfa757-42ba-41c4-b5d6-16b9454eff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4546331-a331-449c-b5b2-ad300bbbf558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 0.99,\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_runtime_client,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24f86512-e2c5-4f54-9714-d9578402b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Given an input question, write a syntactically correct {dialect} query that will be parsed out, validated for systax errors, and run automatically against a database.\n",
    "The question is provided inside a <question> xml tag. Generate the SQL query inside a <sql_query> xml tag.\n",
    "\n",
    "Please only use the following tables inside <table_info>:\n",
    "\n",
    "<table_info>\n",
    "{table_info}.\n",
    "</table_info>\n",
    "\n",
    "1. You must limit the query to {top_k}\n",
    "2. If you need to create an alias use snake case format, e.g new_alias.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"<question>{input}</question>\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bccf49d4-8a04-479c-a6e5-67eefaa52bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dialect', 'input', 'table_info', 'top_k'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dialect', 'table_info', 'top_k'], template='\\nGiven an input question, write a syntactically correct {dialect} query that will be parsed out, validated for systax errors, and run automatically against a database.\\nThe question is provided inside a <question> xml tag. Generate the SQL query inside a <sql_query> xml tag.\\n\\nPlease only use the following tables inside <table_info>:\\n\\n<table_info>\\n{table_info}.\\n</table_info>\\n\\n1. You must limit the query to {top_k}\\n2. If you need to create an alias use snake case format, e.g new_alias.\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='<question>{input}</question>'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69156dbe-9fea-48d0-86d0-5cc513a0df6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a16e478-d15c-41e3-8385-8f4cf3c0ced9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load db\n",
    "tunisia_exports_db = SQLDatabase.from_uri(\"sqlite:////tmp/tunisia-exports.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3096d69-102b-4551-b1b9-939f9088d086",
   "metadata": {},
   "source": [
    "## Ask the LLM to Generate SQL Queries then Handle the Execution Separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e4d89-398c-4db9-a8e8-883adb248871",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate the SQL Query from Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61ced94-bc7b-4d16-8728-7bbbc84c166a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c907d77e-3c81-46b0-be5c-b6a92e28c0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_to_sql_chain = create_sql_query_chain(llm=llm, db=tunisia_exports_db, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd7f1311-0b5c-4da9-88d3-a00a90b2e776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_question = \"Which sector has the highest total gross expert in Tunisia?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a801e29-7fec-47c7-ab9a-2a4a42cc1629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.8 ms, sys: 7.52 ms, total: 64.3 ms\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sql_query>\\nSELECT \\n    t.Sector,\\n    SUM(t.\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table t\\nGROUP BY t.Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;\\n</sql_query>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql_query = text_to_sql_chain.invoke({\"question\": user_question})\n",
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fae1f4c5-bdf2-4434-b29d-97236e0196d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def parse_query(response):\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    sql_query_tag = soup.find('sql_query')\n",
    "    sql_query_text = sql_query_tag.get_text()\n",
    "    return sql_query_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bedef1b7-3d22-4aee-bf30-076e636fa35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT \\n    t.Sector,\\n    SUM(t.\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table t\\nGROUP BY t.Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_query(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2643a-b145-46c1-b023-7a5b34867c0b",
   "metadata": {},
   "source": [
    "### Apply a SQL Linter to Automatically Fix the Query if There is a Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ab8f2-4630-42ff-8176-eecd4526fc1f",
   "metadata": {},
   "source": [
    "After receiving the SQL query, you can validate it, execute it, and potentially call an LLM with the original question and the query answer to formulate a natural language answer. This gives you full control over the query and question answering lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f34f3f-43ec-40bc-8cd0-b5951cad9d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can, for example, run a SQL linter such as [sqlfluff](https://github.com/sqlfluff/sqlfluff) on the SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c56dbed6-1da5-450e-b50c-08faa460ed50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    t.sector,\n",
      "    SUM(t.\"Gross Export\") AS total_gross_export\n",
      "FROM tunisia_exports_table AS t\n",
      "GROUP BY t.sector\n",
      "ORDER BY total_gross_export DESC\n",
      "LIMIT 1;\n",
      "\n",
      "CPU times: user 627 ms, sys: 62.3 ms, total: 690 ms\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sqlfluff\n",
    "\n",
    "fixed_query = sqlfluff.fix(\n",
    "    sql=parse_query(sql_query),\n",
    "    dialect='postgres'\n",
    ") \n",
    "\n",
    "print(fixed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c45971-d492-4b51-abae-141e10af01ab",
   "metadata": {},
   "source": [
    "### Execute the Query Against the Database Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "243580ed-e090-403e-adc7-21cc2037ede2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 µs, sys: 2.44 ms, total: 2.63 ms\n",
      "Wall time: 2.91 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conn = sqlite3.connect(\"/tmp/tunisia-exports.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(fixed_query)\n",
    "result = c.fetchall()\n",
    "result[0]\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5be558e7-1cba-44b4-9119-8f34a8c4edc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Electronics', 4533943713)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f7a326c-edf2-4f71-a124-2fad7d7fa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"/tmp/tunisia-exports.db\")\n",
    "\n",
    "\n",
    "def execute_sql_query(conn, query):\n",
    "    c = conn.cursor()\n",
    "    c.execute(query)\n",
    "    result = c.fetchall()\n",
    "    result[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22e6dd-def2-47dc-be51-a59d5653558f",
   "metadata": {},
   "source": [
    "### Formulate a Natural Language Answer from the Query and Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "802b5c88-0ee5-4a31-9742-1643e7c21456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an AI assistant helping non-technical business users understand data insights clearly and professionally. Your task is to take a business question and SQL query results, and provide a concise answer addressing the question directly, without delving into technical details.\n",
    "\n",
    "Follow these guidelines:\n",
    "\n",
    "1. Understand the context of the question and data.\n",
    "2. Craft a clear, confident answer in a professional tone.\n",
    "3. Focus on key insights and takeaways relevant to the question.\n",
    "4. Use simple, non-technical language.\n",
    "5. Highlight the most important points for quick understanding.\n",
    "\n",
    "Your goal is to communicate actionable insights that empower informed business decisions based on the data, without overwhelming with technical jargon.\n",
    "\n",
    "Provide a concise and professional answer based on the question and SQL results.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"<question>{question}</question><sql_result>{sql_result}</sql_result>\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3c26b79-e0f6-4920-9404-2008fb6b8701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 ms, sys: 0 ns, total: 12.9 ms\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"question\": user_question,\n",
    "        \"sql_result\": json.dumps(result)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c82eef56-d4fd-4924-842f-09a141be0bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the SQL query results, the sector with the highest total gross export in Tunisia is Electronics, with a total gross export value of 4,533,943,713.\n",
      "\n",
      "The key insight here is that the Electronics sector is the top exporting industry in Tunisia, generating significantly more export revenue than other sectors. This suggests the Electronics industry is a major driver of Tunisia's export economy and could be an area of focus for further growth and investment.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ae5dc-1190-4a02-934f-dcf0aa5480c0",
   "metadata": {},
   "source": [
    "## Evaluate on multiple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1433513d-9926-4c0e-8e93-c37e0bc21773",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Which sector has the highest total gross export in Tunisia?\",\n",
    "    \"What are the top 3 sectors with the highest gross export in Tunisia?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d1159e-7f3b-4d7e-a4dc-62daf5757986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.4 ms, sys: 2.25 ms, total: 87.6 ms\n",
      "Wall time: 6.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qa = []\n",
    "for question in questions:\n",
    "    sql_query = text_to_sql_chain.invoke({\"question\": question})\n",
    "    sql_query = parse_query(sql_query)\n",
    "    result = execute_sql_query(conn, sql_query)\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"sql_result\": json.dumps(result)\n",
    "        }\n",
    "    )\n",
    "    qa.append(dict(question=question, answer=response.strip(), sql_query=sql_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b24d9fba-6d4a-4391-84b8-3705ea5cdaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which sector has the highest total gross export in Tunisia?',\n",
       "  'answer': \"Based on the SQL query results, the sector with the highest total gross export in Tunisia is Electronics, with a total export value of 4,533,943,713.\\n\\nThe key insight here is that the Electronics sector is the top exporting industry in Tunisia, significantly outpacing other sectors. This suggests that the Electronics industry is a major driver of Tunisia's export economy and likely plays a critical role in the country's overall economic performance.\",\n",
       "  'sql_query': 'SELECT \\n    t.Sector,\\n    SUM(t.\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table t\\nGROUP BY t.Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;'},\n",
       " {'question': 'What are the top 3 sectors with the highest gross export in Tunisia?',\n",
       "  'answer': \"Based on the SQL query results, the top 3 sectors with the highest gross export in Tunisia are:\\n\\n1. Electronics - $4,533,943,713\\n2. Textiles - $4,099,307,399 \\n3. Services - $2,933,225,232\\n\\nThe electronics sector has the highest gross export value, followed by textiles and then services. These appear to be the key export-oriented industries driving Tunisia's economy.\",\n",
       "  'sql_query': 'SELECT \\n    t.Sector,\\n    SUM(t.\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table t\\nGROUP BY t.Sector\\nORDER BY total_gross_export DESC\\nLIMIT 3;'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c5b0504-137b-47db-a359-75de73f50a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which sector has the highest total gross export in Tunisia?\n",
      "\n",
      " Based on the SQL query results, the sector with the highest total gross export in Tunisia is Electronics, with a total export value of 4,533,943,713.\n",
      "\n",
      "The key insight here is that the Electronics sector is the top exporting industry in Tunisia, significantly outpacing other sectors. This suggests that the Electronics industry is a major driver of Tunisia's export economy and likely plays a critical role in the country's overall economic performance.\n",
      "\n",
      " SELECT \n",
      "    t.Sector,\n",
      "    SUM(t.\"Gross Export\") AS total_gross_export\n",
      "FROM tunisia_exports_table t\n",
      "GROUP BY t.Sector\n",
      "ORDER BY total_gross_export DESC\n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(qa[index][\"question\"] + \"\\n\\n\", qa[index][\"answer\"].strip() + \"\\n\\n\", qa[index][\"sql_query\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72a6baf9-0cff-4ace-96cb-587043ca3baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the top 3 sectors with the highest gross export in Tunisia?\n",
      "\n",
      " Based on the SQL query results, the top 3 sectors with the highest gross export in Tunisia are:\n",
      "\n",
      "1. Electronics - $4,533,943,713\n",
      "2. Textiles - $4,099,307,399 \n",
      "3. Services - $2,933,225,232\n",
      "\n",
      "The electronics sector has the highest gross export value, followed by textiles and then services. These appear to be the key export-oriented industries driving Tunisia's economy.\n",
      "\n",
      " SELECT \n",
      "    t.Sector,\n",
      "    SUM(t.\"Gross Export\") AS total_gross_export\n",
      "FROM tunisia_exports_table t\n",
      "GROUP BY t.Sector\n",
      "ORDER BY total_gross_export DESC\n",
      "LIMIT 3;\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(qa[index][\"question\"] + \"\\n\\n\", qa[index][\"answer\"].strip() + \"\\n\\n\", qa[index][\"sql_query\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e93ab2-6461-469a-baa6-2f4405b650f7",
   "metadata": {},
   "source": [
    "## Improve by Thinking Aloud, Allowing Refusals, and Static Analysis\n",
    "\n",
    "For complex queries, there may be a need to iteratively refine the prompt to arrive at a correct SQL query. This iterative process can be facilitated by incorporating feedback and analysis from various sources. Here are a few approaches we can consider:\n",
    "\n",
    "1. **LLM-Driven Iterative Query Generation**: Ask the LLM to generate an initial SQL query based on the user input. Evaluate this query for syntax correctness and semantic validity with respect to the user's intent. Provide this feedback to the LLM and prompt it to generate an updated version of the query. This cycle can be repeated until a satisfactory query is generated.\n",
    "\n",
    "2. **Static Analysis-Assisted Query Refinement**: After receiving the LLM-generated SQL query, perform static analysis to identify potential errors or issues. This could include checking for syntax errors, type mismatches, missing table or column references, etc. Provide the LLM with the original query and the error messages or analysis results, and ask it to refine the query accordingly.\n",
    "\n",
    "3. **LLM Agent for SQL Query Generation**: Leverage an LLM agent specifically designed for SQL query generation. Such an agent can handle the iterative process of generating, executing, and refining SQL queries automatically. Upon encountering errors or issues during query execution, the agent can autonomously prompt the LLM for an improved query, leveraging the execution feedback and any other relevant context.\n",
    "\n",
    "In addition to these approaches, it may be beneficial to incorporate domain knowledge, data schema information, and examples of correct queries to guide the LLM's understanding of the problem space. Providing clear and structured prompts, along with iterative refinement, can help the LLM generate more accurate and reliable SQL queries, especially for complex scenarios.\n",
    "\n",
    "### Allow Refusal\n",
    "\n",
    "Below we tune the previous prompt to implement the first idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "829411f5-4a70-4eeb-973b-6898ad6ccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Given an input question, write a syntactically correct SQL query in {dialect} that will be parsed out, validated for syntax errors, and run automatically against a database.\n",
    "The question is provided inside a <question> xml tag. Generate the SQL query inside a <sql_query> xml tag.\n",
    "\n",
    "Please follow these guidelines:\n",
    "\n",
    "1. You must limit the query to {top_k} results.\n",
    "2. If you need to create an alias, use snake case format, e.g., new_alias.\n",
    "4. Use the following tables inside <table_info> xml tag.\n",
    "5. Handle edge cases such as ambiguous or incomplete questions by putting .\n",
    "6. Optimize queries for performance by using appropriate indexes, joins, or other techniques when applicable.\n",
    "7. Subqueries, window functions, and other advanced SQL constructs are allowed.\n",
    "\n",
    "<table_info> {table_info} </table_info>\n",
    "\n",
    "<ambiguous>true or false</ambiguous>\n",
    "<ambiguous_reason>explain why you are not able to generate the query when relevant</ambiguous_reason>.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"<question>{input}</question>\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c5639c7-cb15-496d-9e5a-3f641cc6f60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['dialect', 'input', 'table_info', 'top_k'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dialect', 'table_info', 'top_k'], template='\\nGiven an input question, write a syntactically correct SQL query in {dialect} that will be parsed out, validated for syntax errors, and run automatically against a database.\\nThe question is provided inside a <question> xml tag. Generate the SQL query inside a <sql_query> xml tag.\\n\\nPlease follow these guidelines:\\n\\n1. You must limit the query to {top_k} results.\\n2. If you need to create an alias, use snake case format, e.g., new_alias.\\n4. Use the following tables inside <table_info> xml tag.\\n5. Handle edge cases such as ambiguous or incomplete questions by putting .\\n6. Optimize queries for performance by using appropriate indexes, joins, or other techniques when applicable.\\n7. Subqueries, window functions, and other advanced SQL constructs are allowed.\\n\\n<table_info> {table_info} </table_info>\\n\\n<ambiguous>true or false</ambiguous>\\n<ambiguous_reason>explain why you are not able to generate the query when relevant</ambiguous_reason>.\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='<question>{input}</question>'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31ecb7db-5c09-4537-8439-96ec199e509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sql_chain = create_sql_query_chain(llm=llm, db=tunisia_exports_db, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97f5ccc5-c3a4-4bbd-a32d-3aceff09006f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_question = \"Which sector has the highest total gross expert in Tunisia?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aca9e2b-0567-4de1-979a-4926aa092dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 ms, sys: 136 µs, total: 32.7 ms\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sql_query>\\nSELECT \\n  Sector,\\n  SUM(\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table\\nGROUP BY Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;\\n</sql_query>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql_query = text_to_sql_chain.invoke({\"question\": user_question})\n",
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "442d983f-8882-4cbf-a4c5-828a3491ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is the number of car exports in Tunisia?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec87156c-60e6-4de0-9ef4-6469f5b9d5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 ms, sys: 2 ms, total: 38.1 ms\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The given question is ambiguous as it does not specify the type of car exports. The `tunisia_exports_table` does not contain any information about car exports. Without more context about the specific type of car exports, it is not possible to generate a meaningful SQL query to answer this question.\\n\\n<ambiguous>true</ambiguous>\\n<ambiguous_reason>The question does not provide enough information to determine the specific type of car exports to query from the given table.</ambiguous_reason>'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql_query = text_to_sql_chain.invoke({\"question\": user_question})\n",
    "sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151227dd-b0b7-4fe6-8c16-b3aec17b8a07",
   "metadata": {},
   "source": [
    "## Thinking Aloud\n",
    "\n",
    "Below we ask the LLM to think aloud, by evaluating it's first attempt at generating the SQL query before the generating the final query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0daebb9b-9d5a-4ccd-bd67-1eb1169a098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Given an input question, write a syntactically correct SQL query in {dialect} that will be parsed out, validated for syntax errors, and run automatically against a database.\n",
    "The question is provided inside a <question> xml tag. Generate the SQL query inside a <sql_query> xml tag.\n",
    "\n",
    "Please follow these guidelines:\n",
    "\n",
    "1. You must limit the query to {top_k} results.\n",
    "2. If you need to create an alias, use snake case format, e.g., new_alias.\n",
    "4. Use the following tables inside <table_info> xml tag.\n",
    "5. Handle edge cases such as ambiguous or incomplete questions by putting .\n",
    "6. Optimize queries for performance by using appropriate indexes, joins, or other techniques when applicable.\n",
    "7. Subqueries, window functions, and other advanced SQL constructs are allowed.\n",
    "\n",
    "<table_info> {table_info} </table_info>\n",
    "\n",
    "<ambiguous>true or false</ambiguous>\n",
    "<ambiguous_reason>explain why you are not able to generate the query when relevant</ambiguous_reason>.\n",
    "\n",
    "When you have enough information to answer, follow the format below:\n",
    "\n",
    "1. <first_sql_query>put your first attempt here</first_sql_query>\n",
    "2. <evaluation>evaluate if the first sql query meets all requirements and is syntactically correct</evaluation>\n",
    "3. <sql_query>put final sql query here</sql_query>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"<question>{input}</question>\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78bb61c4-1a03-4a37-b12d-738597420ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_sql_chain = create_sql_query_chain(llm=llm, db=tunisia_exports_db, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4441d69-40b2-4025-bc63-574e2b7b76d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_question = \"Which sector has the highest total gross expert in Tunisia?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "233bf575-f8ea-4c7f-84a1-8d2cb63da34f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 ms, sys: 0 ns, total: 31.8 ms\n",
      "Wall time: 2.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<first_sql_query>\\nSELECT Sector, SUM(\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table\\nGROUP BY Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;\\n</first_sql_query>\\n\\n<evaluation>\\nThe first SQL query meets all the requirements and is syntactically correct. It selects the Sector and calculates the total Gross Export for each sector, orders the results by the total_gross_export in descending order, and limits the output to 1 row, which will be the sector with the highest total gross export.\\n</evaluation>\\n\\n<sql_query>\\nSELECT Sector, SUM(\"Gross Export\") AS total_gross_export\\nFROM tunisia_exports_table\\nGROUP BY Sector\\nORDER BY total_gross_export DESC\\nLIMIT 1;\\n</sql_query>'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql_query = text_to_sql_chain.invoke({\"question\": user_question})\n",
    "sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41ac12-a862-423a-afdf-9e67f8c1146a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to set up a dataframe of fake data, store it in a SQLite database to mimic a SQL database, and use an LLM chatbot to generate SQL queries based on natural language questions. We also explored techniques for executing the generated queries, validating them using a SQL linter, and formulating natural language answers based on the query results. The notebook provides a solid foundation for building AI assistants capable of querying databases while adhering to best practices for security and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8f14c-07b1-438b-941a-7917267363a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Environment and Dependency Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "654400ea-4df5-4bed-bfee-e762df302708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'builtins': None,\n",
       " 'IPython.core.interactiveshell': '8.20.0',\n",
       " 'IPython.core.autocall': '8.20.0',\n",
       " 'io': None,\n",
       " 'IPython.core.display': '8.20.0',\n",
       " 'warnings': None,\n",
       " 'pandas': '2.1.4',\n",
       " 'pandas.core.frame': '2.1.4',\n",
       " 'sqlite3': None,\n",
       " 'boto3': '1.34.93',\n",
       " 'botocore.client': '1.34.93',\n",
       " 'langchain_aws.chat_models.bedrock': None,\n",
       " 'json': '2.0.9',\n",
       " 'langchain_core.output_parsers.string': '0.1.46',\n",
       " 'langchain_core.prompts.chat': '0.1.46',\n",
       " 'langchain_community.utilities.sql_database': '0.0.34',\n",
       " 'langchain.chains.sql_database.query': '0.1.16',\n",
       " 'langchain_core.runnables.base': '0.1.46',\n",
       " 'bs4': '4.12.3',\n",
       " '__main__': None,\n",
       " 'sqlfluff': '3.0.5',\n",
       " 'utils.helper': None}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.helper import package_imports\n",
    "dict(package_imports(globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d8a9069-3835-4719-946c-ad148ed786c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux default 4.14.336-257.562.amzn2.x86_64 #1 SMP Sat Feb 24 09:50:35 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db257c55-c2ca-44bb-9b1a-a565da75aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
